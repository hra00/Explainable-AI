{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aebb97e",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "First create the folder structure by unzipping\n",
    "* ```data/ferplus2013/images/images.zip``` for **FER+**\n",
    "* ```data/RAF/images/images.zip``` for **RAF**\n",
    "* ```data/biased.zip``` for **biased RAF**\n",
    "* ```data/binary/images/binaryimages.zip``` for **binary**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222b901",
   "metadata": {},
   "source": [
    "## Binary Dataset\n",
    "* values of the images are RGB from $[0, 255]$\n",
    "* emotion\n",
    "    * happy\n",
    "    * nothappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2eba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataloader import load_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73586d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 20700 images in total\n",
      "Found 16560 validated image filenames belonging to 2 classes.\n",
      "Found 4140 validated image filenames belonging to 2 classes.\n",
      "CPU times: user 271 ms, sys: 161 ms, total: 432 ms\n",
      "Wall time: 590 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "binary_dir = './data/binary/'\n",
    "target_img_size = (100, 100, 3)\n",
    "\n",
    "train_data, test_data = load_binary(binary_dir, target_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ee4b0",
   "metadata": {},
   "source": [
    "## RAF Database\n",
    "* values of the images are RGB from $[0, 255]$\n",
    "* emotions:\n",
    "    * surprise\n",
    "    * fear\n",
    "    * disgust\n",
    "    * happiness\n",
    "    * sadness\n",
    "    * anger\n",
    "    * neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb7d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataloader import load_RAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47228c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 12271 images for traininig\n",
      "Counted 3068 images for testing\n",
      "Found 12271 validated image filenames belonging to 7 classes.\n",
      "Found 3068 validated image filenames belonging to 7 classes.\n",
      "CPU times: user 196 ms, sys: 428 ms, total: 625 ms\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raf_dir = './data/RAF/'\n",
    "target_img_size = (100, 100, 3)\n",
    "\n",
    "train_data, test_data = load_RAF(raf_dir, target_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f814ff0",
   "metadata": {},
   "source": [
    "## Biased RAF Database\n",
    "* values of the images are RGB from $[0, 255]$\n",
    "* emotions:\n",
    "    * surprise\n",
    "    * fear\n",
    "    * disgust\n",
    "    * happiness\n",
    "    * sadness\n",
    "    * anger\n",
    "    * neutral\n",
    "* biases (names of subfolders with respective subset of images):\n",
    "    * male\n",
    "    * female\n",
    "    * caucasian\n",
    "    * asian\n",
    "    * african-american\n",
    "    * 0-3\n",
    "    * 4-19\n",
    "    * 20-39\n",
    "    * 40-69\n",
    "    * 70+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a52a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataloader import load_biased_RAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7858ebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 7314 images for traininig\n",
      "Counted 1819 images for testing\n",
      "Found 7314 validated image filenames belonging to 7 classes.\n",
      "Found 1819 validated image filenames belonging to 7 classes.\n",
      "CPU times: user 277 ms, sys: 89 ms, total: 366 ms\n",
      "Wall time: 379 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raf_dir = './data/biased/'\n",
    "image_dir_name = 'female/' ## example\n",
    "target_img_size = (100, 100, 3)\n",
    "\n",
    "train_data, test_data = load_biased_RAF(raf_dir, image_dir_name, target_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c866b489",
   "metadata": {},
   "source": [
    "## FER plus\n",
    "* values of the images are between $[0, 1]$\n",
    "* emotions:\n",
    "    * anger\n",
    "    * disgust\n",
    "    * fear\n",
    "    * happiness\n",
    "    * neutral\n",
    "    * sadness\n",
    "    * surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataloader import load_FERplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e16c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ferplus_dir = './data/ferplus2013/'\n",
    "target_img_size = (100, 100, 3)\n",
    "\n",
    "train_data, val_data, test_data = load_FERplus(ferplus_dir, target_img_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
